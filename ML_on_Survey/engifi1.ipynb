{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e56517",
   "metadata": {},
   "source": [
    "Reverse-coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee7315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will reverse‑code these questions: ['Q1', 'Q17', 'Q22', 'Q23', 'Q25', 'Q45']\n",
      "Inputs: ['Q5', 'Q6', 'Q10', 'Q11', 'Q12'] …\n",
      "Targets: ['Q1', 'Q2', 'Q3', 'Q4', 'Q7'] …\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = 'Pollfish_Survey_Work_behaviours_survey_393485244_2.xlsx'\n",
    "data_sheet = 'Pollfish_Survey_Work_behaviours'\n",
    "index_sheet = 'Index'     # note the capital “I”\n",
    "\n",
    "\n",
    "df = pd.read_excel(file_path, sheet_name=data_sheet)\n",
    "\n",
    "idx_raw = pd.read_excel(file_path, sheet_name=index_sheet, header=None)\n",
    "\n",
    "#      Keep only the first 12 columns, which correspond to:\n",
    "#    [0] Question coding (e.g. Q1)\n",
    "#    [1] Question text\n",
    "#    [8] Input vs Target flag (“I” or “T”)\n",
    "#    [9] Reverse‑coded flag (“R” if reverse)\n",
    "#    [10] Category\n",
    "#    [11] Possible answers (e.g. “1‑6”)\n",
    "idx = idx_raw.iloc[:, :12].copy()\n",
    "idx.columns = [\n",
    "    'Code', 'Question',\n",
    "    'Skip2', 'Skip3', 'Skip4', 'Skip5', 'Skip6', 'Skip7',\n",
    "    'IorT', 'Reverse', 'Category', 'PossibleAnswers'\n",
    "]\n",
    "\n",
    "# Build lists of codes\n",
    "to_reverse   = idx.loc[idx['Reverse'] == 'R', 'Code'].tolist()\n",
    "inputs       = idx.loc[idx['IorT'] == 'I', 'Code'].tolist()\n",
    "targets      = idx.loc[idx['IorT'] == 'T', 'Code'].tolist()\n",
    "\n",
    "# Apply reverse‑coding (1–6 scales → 7 - x) in the DataFrame\n",
    "for q in to_reverse:\n",
    "    df[q] = 7 - df[q]\n",
    "\n",
    "\n",
    "print(\"Will reverse‑code these questions:\", to_reverse)\n",
    "print(\"Inputs:\", inputs[:5], \"…\")\n",
    "print(\"Targets:\", targets[:5], \"…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88a0ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "Q30\n",
      "3    178\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.drop(index=df[df['Q30'] != 3].index, inplace=True)\n",
    "# List unique values\n",
    "print(df['Q30'].unique())    # should print only [3]\n",
    "\n",
    "# Or get counts\n",
    "print(df['Q30'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26bac5e",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a2c842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each Q‑code to its full question text\n",
    "question_map = idx.set_index('Code')['Question'].to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c22efe",
   "metadata": {},
   "source": [
    "histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402bcec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 34 input histograms to ./histograms_inputs/\n",
      "Saved 49 target histograms to ./histograms_targets/\n"
     ]
    }
   ],
   "source": [
    "# Assumes I have already loaded `df` (survey data) and `idx` (index DataFrame)\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "# 1. Build lookup maps from idx\n",
    "question_map     = idx.set_index('Code')['Question'].to_dict()\n",
    "input_target_map = idx.set_index('Code')['IorT'].to_dict()\n",
    "category_map     = idx.set_index('Code')['Category'].to_dict()\n",
    "reverse_map      = idx.set_index('Code')['Reverse'].to_dict()\n",
    "possible_map     = idx.set_index('Code')['PossibleAnswers'].to_dict()\n",
    "\n",
    "# 2. Identify input and target codes\n",
    "inputs  = idx.loc[idx['IorT'] == 'I', 'Code'].tolist()\n",
    "targets = idx.loc[idx['IorT'] == 'T', 'Code'].tolist()\n",
    "\n",
    "# 3. Prepare output directories\n",
    "dirs = {\n",
    "    'inputs':  'histograms_inputs',\n",
    "    'targets': 'histograms_targets',\n",
    "}\n",
    "for d in dirs.values():\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# 4. Function to plot with counts on bars\n",
    "def save_histograms(codes, output_dir):\n",
    "    for code in codes:\n",
    "        flag      = input_target_map.get(code, '')\n",
    "        label     = 'Input' if flag == 'I' else 'Target'\n",
    "        rev_label = '; Reversed' if reverse_map.get(code) == 'R' else ''\n",
    "        cat       = category_map.get(code, '')\n",
    "        qtxt      = question_map.get(code, code)\n",
    "        \n",
    "        # Title\n",
    "        header     = f\"{code} ({label}{rev_label}) – {cat}\"\n",
    "        full_title = header + \"\\n\" + qtxt\n",
    "        wrapped    = \"\\n\".join(textwrap.wrap(full_title, width=80))\n",
    "        \n",
    "        data = df[code].dropna()\n",
    "        plt.figure(figsize=(8,6))\n",
    "        \n",
    "        # Choose bins\n",
    "        if possible_map.get(code, '').strip() == '1-6':\n",
    "            bins = np.arange(1, 8) - 0.5\n",
    "            xticks = range(1,7)\n",
    "        else:\n",
    "            bins = 10\n",
    "            xticks = None\n",
    "        \n",
    "        counts, bin_edges, patches = plt.hist(data, bins=bins, rwidth=0.8)\n",
    "        if xticks:\n",
    "            plt.xticks(xticks)\n",
    "        \n",
    "        # Annotate counts on each bar\n",
    "        for patch, count in zip(patches, counts):\n",
    "            x = patch.get_x() + patch.get_width() / 2\n",
    "            plt.text(x, count, str(int(count)), ha='center', va='bottom')\n",
    "        \n",
    "        plt.xlabel('Response')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title(wrapped)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/{code}.png\")\n",
    "        plt.close()\n",
    "\n",
    "# 5. Generate histograms for inputs and targets\n",
    "save_histograms(inputs,  dirs['inputs'])\n",
    "save_histograms(targets, dirs['targets'])\n",
    "\n",
    "print(f\"Saved {len(inputs)} input histograms to ./{dirs['inputs']}/\")\n",
    "print(f\"Saved {len(targets)} target histograms to ./{dirs['targets']}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe1eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame now has columns: ['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29', 'Q30', 'Q31', 'Q32', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q38', 'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q46']\n",
      "Inputs: ['Q5', 'Q6', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q16', 'Q17', 'Q19', 'Q20', 'Q23', 'Q24', 'Q25', 'Q28', 'Q29', 'Q34', 'Q35', 'Q36', 'Q38', 'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45']\n",
      "Targets: ['Q1', 'Q2', 'Q3', 'Q4', 'Q7', 'Q8', 'Q9', 'Q15', 'Q18', 'Q21', 'Q22', 'Q26', 'Q27', 'Q31', 'Q32', 'Q33', 'Q37', 'Q46']\n"
     ]
    }
   ],
   "source": [
    "# --- Keep only Q1 through Q46 in your DataFrame and related lists ---\n",
    "\n",
    "# 1. Define the codes to keep\n",
    "keep_codes = [f\"Q{i}\" for i in range(1, 47)]\n",
    "\n",
    "# 2. Subset main DataFrame\n",
    "df = df[keep_codes].copy()\n",
    "\n",
    "# 3. Update inputs and targets lists\n",
    "inputs  = [c for c in inputs  if c in keep_codes]\n",
    "targets = [c for c in targets if c in keep_codes]\n",
    "\n",
    "# 4. (Optional) Also subset your index DataFrame if you use it downstream\n",
    "idx = idx[idx['Code'].isin(keep_codes)].copy()\n",
    "\n",
    "# 5. Rebuild lookup maps need\n",
    "question_map     = idx.set_index('Code')['Question'].to_dict()\n",
    "input_target_map = idx.set_index('Code')['IorT'].to_dict()\n",
    "category_map     = idx.set_index('Code')['Category'].to_dict()\n",
    "reverse_map      = idx.set_index('Code')['Reverse'].to_dict()\n",
    "possible_map     = idx.set_index('Code')['PossibleAnswers'].to_dict()\n",
    "\n",
    "print(f\"DataFrame now has columns: {df.columns.tolist()}\")\n",
    "print(f\"Inputs: {inputs}\")\n",
    "print(f\"Targets: {targets}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be761a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDA tables saved to eda_results\\eda_results.xlsx\n",
      "Correlation heatmap saved to heatmaps\\correlation_heatmap_q1_q46.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "# === ASSUME AGAIN df and idx are already loaded ===\n",
    "\n",
    "\n",
    "# Rebuild input/target lists and lookup maps\n",
    "inputs  = idx[idx['IorT'] == 'I']['Code'].tolist()\n",
    "targets = idx[idx['IorT'] == 'T']['Code'].tolist()\n",
    "question_map     = idx.set_index('Code')['Question'].to_dict()\n",
    "input_target_map = idx.set_index('Code')['IorT'].to_dict()\n",
    "category_map     = idx.set_index('Code')['Category'].to_dict()\n",
    "reverse_map      = idx.set_index('Code')['Reverse'].to_dict()\n",
    "possible_map     = idx.set_index('Code')['PossibleAnswers'].to_dict()\n",
    "\n",
    "# 1. Create output directories\n",
    "os.makedirs('eda_results', exist_ok=True)\n",
    "os.makedirs('heatmaps', exist_ok=True)\n",
    "\n",
    "# 2. Compute EDA tables\n",
    "missing_df = (\n",
    "    df[inputs + targets]\n",
    "    .isna()\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "missing_df.columns = ['Variable', 'MissingPercent']\n",
    "\n",
    "desc_df = df[inputs].describe()\n",
    "\n",
    "corr_df = df[inputs + targets].corr()\n",
    "\n",
    "# 3. Save EDA tables to Excel\n",
    "eda_excel_path = os.path.join('eda_results', 'eda_results.xlsx')\n",
    "with pd.ExcelWriter(eda_excel_path) as writer:\n",
    "    missing_df.to_excel(writer, sheet_name='Missingness', index=False)\n",
    "    desc_df.to_excel(writer, sheet_name='Descriptives')\n",
    "    corr_df.to_excel(writer, sheet_name='Correlations')\n",
    "\n",
    "# 4. Plot and save correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "cax = ax.imshow(corr_df, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax, fraction=0.046, pad=0.04, ax=ax)\n",
    "ax.set_xticks(np.arange(len(corr_df)))\n",
    "ax.set_yticks(np.arange(len(corr_df)))\n",
    "ax.set_xticklabels(corr_df.columns, rotation=90, fontsize=6)\n",
    "ax.set_yticklabels(corr_df.index, fontsize=6)\n",
    "ax.set_title('Correlation Heatmap: Q1–Q46')\n",
    "plt.tight_layout()\n",
    "heatmap_path = os.path.join('heatmaps', 'correlation_heatmap_q1_q46.png')\n",
    "fig.savefig(heatmap_path, dpi=150)\n",
    "plt.close(fig)\n",
    "\n",
    "print(f\"EDA tables saved to {eda_excel_path}\")\n",
    "print(f\"Correlation heatmap saved to {heatmap_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bea1ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering done (K=2).\n",
      "Files saved in 'cluster_results': elbow.png, silhouette.png, pca_scatter.png, cluster_profiles.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Kmeans clustering\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Assumes df and inputs list are already defined\n",
    "\n",
    "# 1. Prepare output directory\n",
    "out_dir = 'cluster_results'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# 2. Standardize inputs\n",
    "X = df[inputs]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# 3. Elbow & Silhouette analysis\n",
    "sse, silh = [], []\n",
    "Klist = range(2, 12)\n",
    "for k in Klist:\n",
    "    km = KMeans(n_clusters=k, random_state=42).fit(X_scaled)\n",
    "    sse.append(km.inertia_)\n",
    "    silh.append(silhouette_score(X_scaled, km.labels_))\n",
    "\n",
    "# 4. Save Elbow plot\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(Klist, sse, marker='o')\n",
    "plt.xlabel('K'); plt.ylabel('SSE'); plt.title('Elbow Method')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{out_dir}/elbow.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# 5. Save Silhouette plot\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(Klist, silh, marker='o')\n",
    "plt.xlabel('K'); plt.ylabel('Avg Silhouette'); plt.title('Silhouette Analysis')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{out_dir}/silhouette.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# 6. Choose best K and fit final model\n",
    "best_k = Klist[np.argmax(silh)]\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42).fit(X_scaled)\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "# 7. PCA for 2D scatter\n",
    "pca2 = PCA(n_components=2, random_state=42).fit(X_scaled)\n",
    "pcs = pca2.transform(X_scaled)\n",
    "df['PC1'], df['PC2'] = pcs[:,0], pcs[:,1]\n",
    "\n",
    "# 8. Save PCA scatter plot\n",
    "plt.figure(figsize=(6,5))\n",
    "for c in range(best_k):\n",
    "    pts = df[df['cluster']==c]\n",
    "    plt.scatter(pts['PC1'], pts['PC2'], label=f'Cluster {c}', s=20)\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2'); plt.title('Cluster PCA Scatter')\n",
    "plt.legend(); plt.tight_layout()\n",
    "plt.savefig(f'{out_dir}/pca_scatter.png', dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# 9. Compute & save cluster profiles\n",
    "profiles = df.groupby('cluster')[inputs].mean().round(2)\n",
    "profiles.to_excel(f'{out_dir}/cluster_profiles.xlsx', index=True)\n",
    "\n",
    "print(f\"Clustering done (K={best_k}).\")\n",
    "print(f\"Files saved in '{out_dir}': elbow.png, silhouette.png, pca_scatter.png, cluster_profiles.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7bfdd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Target  Accuracy  F1_macro\n",
      "0      Q1  0.361111  0.242308\n",
      "1      Q2  0.472222  0.321270\n",
      "2      Q3  0.527778  0.402412\n",
      "3      Q4  0.472222  0.276405\n",
      "4      Q7  0.222222  0.098765\n",
      "5      Q8  0.388889  0.184052\n",
      "6      Q9  0.333333  0.167246\n",
      "7     Q15  0.444444  0.324359\n",
      "8     Q18  0.388889  0.213276\n",
      "9     Q21  0.388889  0.263149\n",
      "10    Q22  0.222222  0.180122\n",
      "11    Q26  0.388889  0.190789\n",
      "12    Q27  0.472222  0.421967\n",
      "13    Q31  0.555556  0.273275\n",
      "14    Q32  0.694444  0.462963\n",
      "15    Q33  0.500000  0.271230\n",
      "16    Q37  0.666667  0.405556\n",
      "17    Q46  0.500000  0.372161\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput    import MultiOutputClassifier\n",
    "from sklearn.pipeline       import Pipeline\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "from sklearn.ensemble       import RandomForestClassifier\n",
    "from sklearn.metrics        import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Define X and y\n",
    "X = df[inputs]\n",
    "y = df[targets]   # multi‐output DataFrame\n",
    "\n",
    "# 2. Train / test split (no stratify)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Build pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', MultiOutputClassifier(\n",
    "        RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4. Fit\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 5. Predict\n",
    "y_pred = pd.DataFrame(\n",
    "    pipeline.predict(X_test),\n",
    "    columns=targets,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# 6. Evaluate\n",
    "results = []\n",
    "for col in targets:\n",
    "    acc = accuracy_score(y_test[col], y_pred[col])\n",
    "    f1  = f1_score(y_test[col], y_pred[col], average='macro')\n",
    "    results.append({'Target': col, 'Accuracy': acc, 'F1_macro': f1})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_excel('multioutput_classification_results.xlsx', index=False)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10039f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.14      1.00      0.25         1\n",
      "           3       0.33      0.36      0.35        11\n",
      "           4       0.20      0.27      0.23        11\n",
      "           5       0.00      0.00      0.00         7\n",
      "           6       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.25        36\n",
      "   macro avg       0.28      0.31      0.19        36\n",
      "weighted avg       0.31      0.25      0.23        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\ML Training\\mltraining\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\USER\\Desktop\\ML Training\\mltraining\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\USER\\Desktop\\ML Training\\mltraining\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Choose a target with very few minority samples, e.g. Q7\n",
    "y_col = 'Q7'\n",
    "X = df[inputs]\n",
    "y = df[y_col]\n",
    "\n",
    "# 2. Train/test split (no stratify)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Build pipeline with SMOTE using k_neighbors small enough for your smallest class\n",
    "#    Here we set k_neighbors=2 because y_train.min() class has only 3 samples\n",
    "pipe = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42, k_neighbors=2)),\n",
    "    ('clf', RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# 4. Fit & evaluate\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8092940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\ML Training\\mltraining\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\Desktop\\ML Training\\mltraining\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\USER\\Desktop\\ML Training\\mltraining\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\USER\\Desktop\\ML Training\\mltraining\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\USER\\Desktop\\ML Training\\mltraining\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogisticRegression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.40      0.55      0.46        11\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.40      0.29      0.33         7\n",
      "           6       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.22        36\n",
      "   macro avg       0.13      0.14      0.13        36\n",
      "weighted avg       0.20      0.22      0.21        36\n",
      "\n",
      "\n",
      "=== HistGradientBoosting ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.38      0.55      0.44        11\n",
      "           4       0.18      0.18      0.18        11\n",
      "           5       0.00      0.00      0.00         7\n",
      "           6       0.50      0.20      0.29         5\n",
      "\n",
      "    accuracy                           0.25        36\n",
      "   macro avg       0.18      0.15      0.15        36\n",
      "weighted avg       0.24      0.25      0.23        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# 1. Choose your target\n",
    "y_col = 'Q7'  # replace with whichever question you're modeling\n",
    "X = df[inputs]\n",
    "y = df[y_col]\n",
    "\n",
    "# 2. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Define two pipelines with different classifiers\n",
    "pipelines = {\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('smote', SMOTE(random_state=42, k_neighbors=2)),\n",
    "        ('clf', LogisticRegression(multi_class='multinomial', max_iter=1000, random_state=42))\n",
    "    ]),\n",
    "    'HistGradientBoosting': Pipeline([\n",
    "        ('smote', SMOTE(random_state=42, k_neighbors=2)),\n",
    "        ('clf', HistGradientBoostingClassifier(random_state=42))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# 4. Fit and print classification reports\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebfc22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\ML Training\\mltraining\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\USER\\Desktop\\ML Training\\mltraining\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\USER\\Desktop\\ML Training\\mltraining\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM + SMOTE results exported to 'svm_results'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. Load and prepare data ---\n",
    "file_path   = 'Pollfish_Survey_Work_behaviours_survey_393485244_2.xlsx'\n",
    "data_sheet  = 'Pollfish_Survey_Work_behaviours'\n",
    "idx_sheet   = 'Index'\n",
    "\n",
    "df_full = pd.read_excel(file_path, sheet_name=data_sheet)\n",
    "idx_raw = pd.read_excel(file_path, sheet_name=idx_sheet, header=None)\n",
    "idx = idx_raw.iloc[:, :12].copy()\n",
    "idx.columns = [\n",
    "    'Code','Question','Skip2','Skip3','Skip4','Skip5','Skip6','Skip7',\n",
    "    'IorT','Reverse','Category','PossibleAnswers'\n",
    "]\n",
    "\n",
    "# Keep only Q1–Q46\n",
    "keep_codes = [f\"Q{i}\" for i in range(1, 47)]\n",
    "df = df_full[keep_codes].copy()\n",
    "idx = idx[idx['Code'].isin(keep_codes)].copy()\n",
    "inputs = idx[idx['IorT'] == 'I']['Code'].tolist()\n",
    "\n",
    "# --- 2. Specify target ---\n",
    "y_col = 'Q7'  # change to your target\n",
    "\n",
    "# --- 3. Split data ---\n",
    "X = df[inputs]\n",
    "y = df[y_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- 4. Build pipeline with SMOTE + scaling + SVM ---\n",
    "svm_pipe = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42, k_neighbors=2)),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('svm', SVC(kernel='rbf', probability=True, class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# --- 5. Cross-validate on training set ---\n",
    "cv_acc = cross_val_score(svm_pipe, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cv_f1  = cross_val_score(svm_pipe, X_train, y_train, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "\n",
    "# --- 6. Fit & predict on test set ---\n",
    "svm_pipe.fit(X_train, y_train)\n",
    "y_pred = svm_pipe.predict(X_test)\n",
    "\n",
    "# --- 7. Compute test metrics ---\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "test_f1  = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# --- 8. Export results ---\n",
    "res_dir = 'svm_results'\n",
    "os.makedirs(res_dir, exist_ok=True)\n",
    "\n",
    "# Performance metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['CV Accuracy', 'CV F1_macro', 'Test Accuracy', 'Test F1_macro'],\n",
    "    'Value': [cv_acc.mean(), cv_f1.mean(), test_acc, test_f1],\n",
    "    'StdDev': [cv_acc.std(), cv_f1.std(), np.nan, np.nan]\n",
    "})\n",
    "metrics_df.to_excel(os.path.join(res_dir, 'svm_performance_metrics.xlsx'), index=False)\n",
    "\n",
    "# Detailed classification report\n",
    "report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "report_df.to_excel(os.path.join(res_dir, 'svm_classification_report.xlsx'), index=True)\n",
    "\n",
    "# Confusion matrix plot\n",
    "cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='.2f', cmap='Blues',\n",
    "    xticklabels=svm_pipe.named_steps['svm'].classes_,\n",
    "    yticklabels=svm_pipe.named_steps['svm'].classes_\n",
    ")\n",
    "plt.title(f'Confusion Matrix for {y_col}')\n",
    "plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(res_dir, 'svm_confusion_matrix.png'), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(f\"SVM + SMOTE results exported to '{res_dir}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mltraining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
